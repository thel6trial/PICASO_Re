{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4309c97-f3ef-4cb1-9365-66276c338904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d1c85b-fd6d-49b3-a7c0-f27e6ccd91c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5926defafa754450abd024af64f3b734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id='meta-llama/Llama-2-7b-hf'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map='auto', torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff63588-72ac-48ef-a099-47a960f4e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "MAX_NEW_TOKENS = 128\n",
    "model_name = 'meta-llama/Llama-2-7b-hf'\n",
    "\n",
    "text = 'Hamburg is in which country?\\n'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae32d25-e8a6-4947-bf1b-2bba0e0ba1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe46d51f-995d-4acf-a436-d5ba0482b524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] What is a large language model? [/INST]\n",
      "[INST] What is a large language model? [/INST]\n",
      "What is a large language model?\n",
      "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on a large amount of text data to generate human-like text. LLMs are typically used for natural language processing (NLP) tasks such as language translation, text generation, and question answering.\n",
      "LLMs are trained on large datasets of text data, such as books, articles, and social media posts. The training process involves feeding the model a large amount of text data and teaching it to recognize patterns and relationships between words and phrases. The model then generates text that is similar to the data it was trained on.\n",
      "LLMs are often used in NLP tasks such as language translation, text generation, and question answering. For example, an LLM can be\n"
     ]
    }
   ],
   "source": [
    "# Ignore warnings\n",
    "# logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"What is a large language model?\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776761f0-933b-42d4-8879-2b8414d2492c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
